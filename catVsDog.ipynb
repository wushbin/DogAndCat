{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "train_filenames = os.listdir('train')\n",
    "train_cat = filter(lambda x : x[:3]=='cat', train_filenames)\n",
    "train_dog = filter(lambda x : x[:3]=='dog', train_filenames)\n",
    "\n",
    "def rmrf_mkdir(dirname):\n",
    "    if os.path.exists(dirname):\n",
    "        shutil.rmtree(dirname)\n",
    "    os.mkdir(dirname)\n",
    "    \n",
    "rmrf_mkdir('train2')\n",
    "os.mkdir('train2/cat')\n",
    "os.mkdir('train2/dog')\n",
    "rmrf_mkdir('test2')\n",
    "os.symlink('../test/','test2/test')\n",
    "\n",
    "for fileName in train_cat:\n",
    "    os.symlink('../../train/'+fileName, 'train2/cat/'+fileName)\n",
    "for fileName in train_dog:\n",
    "    os.symlink('../../train/'+fileName, 'train2/dog/'+fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "TRAIN_DIR = 'train'\n",
    "TEST_DIR = 'test'\n",
    "\n",
    "ROWS = 128\n",
    "COLS = 128\n",
    "CHANNELS = 3\n",
    "\n",
    "train_images = [os.path.join(TRAIN_DIR, f) for f in os.listdir(TRAIN_DIR)] # use this for full dataset\n",
    "train_dogs =   [os.path.join(TRAIN_DIR, f) for f in os.listdir(TRAIN_DIR) if 'dog' in f]\n",
    "train_cats =   [os.path.join(TRAIN_DIR, f) for f in os.listdir(TRAIN_DIR) if 'cat' in f]    \n",
    "\n",
    "test_images =  [os.path.join(TEST_DIR, f) for f in os.listdir(TEST_DIR)]\n",
    "\n",
    "#cut down the size of train_images\n",
    "#train_images = train_dogs[:1000] + train_cats[:1000]\n",
    "train_images = train_dogs + train_cats\n",
    "random.shuffle(train_images)\n",
    "test_images =  test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_image(file_path):\n",
    "    img = cv2.imread(file_path, cv2.IMREAD_COLOR) #cv2.IMREAD_GRAYSCALE #cv2.IMREAD_COLOR #cv2.IMREAD_UNCHANGED\n",
    "    return cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "labels = []\n",
    "for i in train_images:\n",
    "    if 'dog' in i:\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)\n",
    "\n",
    "sns.countplot(labels)\n",
    "sns.plt.title('Cats and Dogs')\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_cats_and_dogs(idx):\n",
    "    cat = read_image(train_cats[idx])\n",
    "    dog = read_image(train_dogs[idx])\n",
    "    pair = np.concatenate((cat, dog), axis=1)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.imshow(pair)\n",
    "    plt.show()\n",
    "    \n",
    "for idx in range(0,5):\n",
    "    show_cats_and_dogs(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = train_images[:-5000]\n",
    "train_labels = labels[:-5000]\n",
    "valid_set = train_images[-5000:]\n",
    "valid_labels = labels[-5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#feature_det = cv2.FeatureDetector_create(\"SIFT\")\n",
    "#descr_ext = cv2.DescriptorExtractor_create(\"SIFT\")\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "def preProcessImages(image_paths):\n",
    "    descriptors= []\n",
    "    for image_path in tqdm(image_paths):\n",
    "        im = read_image(image_path)\n",
    "        gray_im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "        kpts, des = sift.detectAndCompute(gray_im, None)\n",
    "        descriptors.append(des)\n",
    "    return descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_descriptors = preProcessImages(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.svm import SVC\n",
    "flann_params = dict(algorithm = 1, trees = 5)\n",
    "matcher = cv2.FlannBasedMatcher(flann_params, {})\n",
    "bow_extract  =cv2.BOWImgDescriptorExtractor(sift,matcher)\n",
    "bow_train = cv2.BOWKMeansTrainer(20)\n",
    "\n",
    "def generateDic(bow_train, descriptors):\n",
    "    print('Start adding descriptors')\n",
    "    for des in tqdm(descriptors):\n",
    "        bow_train.add(des)\n",
    "    print('Start creating dictionary')\n",
    "    voc = bow_train.cluster()\n",
    "    return voc\n",
    "\n",
    "def getTrainFeature(voc, bow_extract, image_paths):\n",
    "    bow_extract.setVocabulary(voc)\n",
    "    traindata = []\n",
    "    print('Start generating features')\n",
    "    for imagepath in tqdm(image_paths):\n",
    "        featureset = getImagedata(sift,bow_extract,imagepath)\n",
    "        traindata.extend(featureset)\n",
    "    return traindata\n",
    "\n",
    "def getImagedata(sift,bow_extract,path):\n",
    "    im = read_image(path)\n",
    "    gray_im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    featureset = bow_extract.compute(gray_im, sift.detect(gray_im))\n",
    "    return featureset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainModle(traindata, image_classes):\n",
    "    #clf = LinearSVC()\n",
    "    clf = SVC(C = 1000000,kernel='rbf' )\n",
    "    clf.fit(traindata, np.array(image_classes))\n",
    "    joblib.dump(clf, \"imagereco.pkl\", compress=3)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "voc = generateDic(bow_train,train_descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traindata = getTrainFeature(voc, bow_extract, train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#clf = train(train_descriptors, labels, train_images)\n",
    "clf = trainModle(traindata,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "voc = joblib.load(\"dictionary.pkl\")\n",
    "clf = joblib.load(\"imagereco.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm  \n",
    "\n",
    "flann_params = dict(algorithm = 1, trees = 5)     \n",
    "matcher = cv2.FlannBasedMatcher(flann_params, {})\n",
    "bow_extract  =cv2.BOWImgDescriptorExtractor(sift,matcher)\n",
    "bow_extract.setVocabulary( voc )\n",
    "testing_classes = test_images\n",
    "imgPath=[]\n",
    "\n",
    "type=[]\n",
    "valid_pred = []\n",
    "for test_imagepath in tqdm(valid_set):\n",
    "    featureset = getImagedata(sift,bow_extract,test_imagepath)\n",
    "    prediction = clf.predict(featureset)\n",
    "    valid_pred.append(prediction[0])\n",
    "    if prediction ==1:\n",
    "        predictText = \"DOG\"\n",
    "    elif prediction ==0:\n",
    "        predictText = \"CAT\"\n",
    "    type.append(predictText)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(valid_labels,valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_images =  [os.path.join(TEST_DIR, f) for f in os.listdir(TEST_DIR)]\n",
    "#test_images =  test_images[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#def predict(voc,clf):\n",
    "flann_params = dict(algorithm = 1, trees = 5)     \n",
    "matcher = cv2.FlannBasedMatcher(flann_params, {})\n",
    "bow_extract  =cv2.BOWImgDescriptorExtractor(sift,matcher)\n",
    "bow_extract.setVocabulary( voc )\n",
    "\n",
    "#testImageFolder = \"../../../data/images/testimage/\"\n",
    "#testing_classes = os.listdir(testImageFolder)\n",
    "\n",
    "testing_classes = test_images\n",
    "imgPath=[]\n",
    "\n",
    "    #for foldername in testing_classes:\n",
    "        #dir = os.path.join(testImageFolder, foldername)\n",
    "        #for root, dirs, files in os.walk(dir):\n",
    "            #for file in files:\n",
    "                #imgPath.append(dir+\"/\"+file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_images[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type=[]\n",
    "for test_imagepath in test_images:\n",
    "    featureset = getImagedata(sift,bow_extract,test_imagepath)\n",
    "    prediction = clf.predict(featureset)\n",
    "    if prediction ==1:\n",
    "        predictText = \"DOG\"\n",
    "    elif prediction ==0:\n",
    "        predictText = \"CAT\"\n",
    "    type.append(predictText)\n",
    "type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# for test_imagepath in test_images:\n",
    "#     img = read_image(test_imagepath)\n",
    "#     plt.figure(figsize=(10,5))\n",
    "#     plt.imshow(img)\n",
    "#     plt.annotate('cat', xy=(2, 1), xytext=(10, 5))\n",
    "#     plt.show()\n",
    "for i in range(0,25):\n",
    "    img = read_image(test_images[i])\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.imshow(img)\n",
    "    plt.annotate(type[i], xy=(2, 1),size= 25,color='#ee8d18', xytext=(10, 10))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = test_images[1]\n",
    "a = a.split('/')[1]\n",
    "num = a.split('.')[0]\n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "with open('submission_file.csv','w') as f:\n",
    "    f.write('id,label\\n')        \n",
    "with open('submission_file.csv','a') as f:\n",
    "    for img in tqdm(test_images):\n",
    "        temp = img.split('/')[1]\n",
    "        img_num = temp.split('.')[0]\n",
    "        featureset = getImagedata(sift,bow_extract,img)\n",
    "        prediction = clf.predict(featureset)\n",
    "        f.write('{},{}\\n'.format(img_num,prediction[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
